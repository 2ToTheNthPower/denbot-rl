training:
  gamma: 0.99
  lambda_: 0.95
  lr: 1e-5
  entropy_coeff: 0.005
  train_batch_size_per_learner: 8192
  num_epochs: 32
  minibatch_size: 2048
  shuffle_batch_per_epoch: True
  use_kl_loss: false

rl_module:
  model_config:
    fcnet_hiddens: [256, 256]
      # grid_search: [[256, 256], [256, 256, 256]]
    fcnet_activation: LeakyReLU
